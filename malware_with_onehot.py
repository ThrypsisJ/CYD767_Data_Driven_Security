import pyarrow.csv as pcsv
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import pickle
import operator
from os import listdir
from os.path import exists
from random import shuffle
from tqdm import tqdm

class sequence(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(sequence, self).__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, 1, batch_first=True)
        self.linear = nn.Linear(hidden_dim, 1, bias=True)
        self.sig = nn.Sigmoid()

    def forward(self, input):
        _, out_0 = self.gru(input)
        out_1 = self.linear(out_0)
        out_2 = self.sig(out_1)
        return out_2

class mal_onehot():
    def __init__(self, hidden_dim):
        self.word_dict = self.load_dict()
        self.seq = sequence(len(self.word_dict), hidden_dim).to('cuda')
        self.opt = optim.Adam(self.seq.parameters(), lr=0.01)
        self.loss = nn.BCELoss()

    def load_dict(self):
        f = open('./dataset/word_dict.pkl', 'rb')
        word_dict = pickle.load(f)
        word_dict = dict(sorted(word_dict.items(), key=operator.itemgetter(1), reverse=True))
        return word_dict

    def load_params(self):
        param_file = torch.load('./parameters/param')
        self.seq.load_state_dict(param_file)

    def save_params(self):
        torch.save(self.seq.state_dict(), './parameters/param')

    def train(self):
        if exists('./parameters/param'): self.load_params()
        path = './dataset/processed_train'
        file_list = listdir(path)
        shuffle(file_list)
        labels = pcsv.read_csv('./dataset/train_label.csv').to_pandas()

        TP, TN, FP, FN = 0, 0, 0, 0

        for file in tqdm(file_list):
        #for file in file_list:
            truth = labels[labels['filename']==file[:-4]]['label'].tolist()
            truth = torch.tensor([[truth]], dtype=torch.float, device='cuda')
            try:
                csv_file = pcsv.read_csv(f'{path}/{file}').to_pandas()['api']
                
                if len(csv_file)==0: continue
                for word_idx in range(len(csv_file)):
                    csv_file.iloc[word_idx] = self.word_dict[csv_file.iloc[word_idx]]

                input_t = torch.tensor(csv_file, device='cuda', dtype=torch.float).unsqueeze(0)
                output = self.seq(input_t)
                
                if output >= 0.5 and truth > 0.5: TP += 1
                if output >= 0.5 and truth < 0.5: FP += 1
                if output < 0.5 and truth < 0.5: TN += 1
                if output < 0.5 and truth > 0.5: FN += 1

                loss = self.loss(output, truth)
                self.opt.zero_grad()
                loss.backward()
                self.opt.step()
            except:
                continue
        
        acc = (TP+TN) / (TP+TN+FP+FN)
        pre = (TP) / (TP+FP) if (TP+FP) != 0 else 0.
        rec = (TP) / (TP+FN) if (TP+FN) != 0 else 0.
        f1 = 2 * (pre*rec) / (pre+rec)
        print(f'[Result] Accuracy: {acc} / Precision: {pre} / Recall: {rec} / F1 score: {f1}\n')


    def test(self):
        path = './dataset/processed_test'
        file_list = listdir(path)
        result = {}

        for file in tqdm(file_list):
            csv_file = pcsv.read_csv(f'{path}/{file}').to_pandas()['api']
            answer = 0
            try:
                if not len(csv_file)==0:
                    for word_idx in range(len(csv_file)):
                        csv_file.iloc[word_idx] = self.word_dict[csv_file.iloc[word_idx]]

                    input_t = torch.tensor(csv_file, device='cuda', dtype=torch.float)
                    output = self.seq(input_t)
                    answer = 1 if output >= 0.5 else 0
            except:
                pass

            result[file[:-4]] = answer
        
        df = pd.DataFrame(result)
        df.to_csv('./dataset/test_label.csv')